# Loss Function 

***to evaluate GOODNESS OF MODEL!!!! (the ability of generalization)***



## MSE Loss

它通常用于回归问题。在回归问题中，我们试图预测一个连续的数值，比如预测房价、股票价格等。MSE会计算模型预测值与真实值之间的平均平方差，衡量预测值与真实值之间的偏差。MSE的值越小，说明模型的预测效果越好。

```python
Loss = torch.nn.MSELoss()
```



## Cross Entropy Loss

它通常用于分类问题。在分类问题中，我们试图预测一个离散的类别标签，如图像分类、文本分类等。交叉熵损失衡量的是模型预测的概率分布与真实的概率分布之间的距离，是衡量模型预测概率与真实情况一致性的一个度量。交叉熵损失值越小，说明模型的预测效果越好。

在多分类问题中，我们常常使用**softmax**函数将网络的输出**转换为概率分布**。这个预估的概率分布Q与数据的真实分布P（通常是one-hot编码，只有真实类别的位置为1，其余为0）之间的差异，就可以用交叉熵损失来度量：
$$
L = - Σ P(x) log Q(x)
$$
其中，∑表示对所有可能的事件求和，p(x)是真实分布下事件x发生的概率，q(x)是预测分布下事件x发生的概率。

```python
Loss = torch.nn.CrossEntropy()  # 已经包含Softmax（自动将一层Softmax加到模型输出后）！！！！！！！
```

这就是交叉熵损失。你可以看到，它在形式上就是P和Q的交叉熵。如果网络的预测很准确（也就是说，Q接近于P），那么交叉熵损失就会很小。反之，如果网络的预测偏离了真实情况（也就是说，Q远离了P），那么交叉熵损失就会变大。

在多分类问题中，目标类别通常是用"one-hot"编码来表示的，即在真实类别对应的位置上为1，其他位置为0。这样的编码方式，我们称为P。

下面用一个形象的例子来解释这个公式。

假设你在进行一个图片分类任务，每张图片都应被分为猫、狗、或鸟其中的一种。对于一张特定的图片，它真实的标签可能是"猫"，那么真实分布P就是 [1, 0, 0]。也就是说，这张图片是猫的概率是1，是狗或鸟的概率都是0。

然后，你的模型可能预测这张图片为猫、狗、鸟的概率分别是0.7、0.2、0.1，那么你的预测分布Q就是 [0.7, 0.2, 0.1]。

那么，对于这张图片，交叉熵就是：`Cross-Entropy = - (1 * log(0.7) + 0 * log(0.2) + 0 * log(0.1))`。可以看到，如果你的预测分布完全正确，那么交叉熵就为0，因为`-log(1) = 0`；但如果你的预测分布完全错误，比如你预测这张图片是猫的概率为0，那么交叉熵就会变为无穷大，因为`-log(0)`为无穷大。



## Use Maximum Likelihood instead

**似然函数（Likelihood）**在机器学习中的含义：建立的模型（所假设的分布）能生成（generate，即sample\<`v.`>，抽样出）训练集的可能性（likelihood），即训练集属于该假设的分布的可能性、训练集真实所属分布与该假设的分布的相似度**（事实上似然函数取对数后的相反数就是 Cross Entropy！！！）**。

![image-20230723114252239](images/image-20230723114252239.png)

对分类问题采用概率模型，便可以使用连续的**似然函数**的值作为模型评估对象，通过优化预估分布函数和其参数的估计公式（关于训练集的统计量）来使似然函数最大即可实现对模型本身的优化。



## Hinge Loss

<img src="images/statistical_learning_7.6.png" alt="statistical_learning_7.6" style="zoom: 67%;" />

<img src="images/v2-3c6aa9626ee8e4609b0d7c5712baf624_r.jpg" alt="v2-3c6aa9626ee8e4609b0d7c5712baf624_r" style="zoom:67%;" />

### 对于二元分类

**合页损失函数（Hinge Loss）**的定义如下：
$$
对于单个训练样本点：\quad
loss=max(0,1−(y′∗y))
$$
其中“$y'$”表示<u>当前学得的</u>**分类器模型的输出**：
$$
y′=b+w1\cdot x1+w2\cdot x2+…wn\cdot xn
$$
“$y$”表示**真标签（ground truth label）**，<u>值为 -1 或 +1</u>；

$y′∗y$ 表示**函数间隔**，即该训练样本点和**决策边界（$W\cdot x+b=0$）**的**实际距离**；

>   *<u>软间隔（Soft Margin）</u>* --- 允许少数训练样本点在**安全间隔（Safe Margin）** 内部，优化时需要最小化这样的样本数
>
>   <img src="images/v2-a04fdb43f41bd9e4fd06306558ab61f2_r.jpg" alt="v2-a04fdb43f41bd9e4fd06306558ab61f2_r" style="zoom:67%;" />
>
>   *<u>硬间隔（Hard Margin）</u>* --- 要求所有训练样本点均在**安全间隔（Safe Margin）** 外侧

==**优化目标：**找到满足“软”或“硬”要求的**安全间隔**的**最大值**==

***安全间隔也可理解为对刚好分类正确的结果的适度惩罚，刚好正确（在决策边界上）是不足够的，需要充分正确（和决策边界拉开一定距离）才是成功分类（对未见数据达到一定包容度）***

$1−(y′∗y)$ 中的 $1$ 为**距离因子**，非0即可，与实际的最优距离无关，学得的 $W$ 和 $b$ 会随之按比例变化。

### 对于多元分类

>   <img src="images/image-20230812094317357.png" alt="image-20230812094317357" style="zoom: 67%;" />
>
>   ('$S_j$' is the score of class_j for sample_i; '$S_{yi}$' is the score of the ground truth label_y of sample_i from the current classifier)
>
>   **Margin:** $S_{yi}-S_j$
>
>   $S_{yi}$ need to be higher than $S_j$ by some safety margin. Simply  ≥ is not enough.

### 平方合页损失

将函数间隔值平方代入线性合页损失函数。

![v2-5a06117632b3e2dabed408c5b2b6e405_1440w](images/v2-5a06117632b3e2dabed408c5b2b6e405_1440w.jpg)

与常规合页损失函数相比，平方合页损失函数对离群值的惩罚更严厉（Very very bad => Squared bad），而对小损失值（函数间隔小于1）的惩罚减小（平方比原值更小）。





## To Prevent Overfitting: L2 Regularization

L2正则化是一种常用的防止过拟合的技术，也被称为权重衰减。它的基本思想是通过在损失函数中添加一个额外的项来惩罚大的权重值，从而**防止模型过于复杂**。

这种<u>**额外的项用来描述模型复杂度**</u>，是模型权重的平方和的一部分，因此称为"L2"正则化。

具体来说，如果没有正则化，我们的目标可能只是最小化损失函数（例如，均方误差）：

$$
L = Σ(y - f(x))^2
$$
在这里，y是真实的目标值，f(x)是模型的预测值。

当我们加入L2正则化时，我们的目标变为最小化损失函数和正则化项之和：

$$
L = \lambdaΣ(y - f(x))^2 + (1-λ)Σw^2,\ \lambda\in(0,1)\\
或\\
L = Σ(y - f(x))^2 + λΣw^2,\ \lambda\in(0,1)
$$
在这里，$w$ 代表模型的权重，<u>$λ$ 是一个超参数，**或者用交叉验证法估计**，控制正则化的强度，即**经验误差和网络复杂度的平衡因子**</u>。请注意，<u>**正则化项 $Σw^2$ 是所有权重平方的和**</u>。

通过这种方式，L2正则化鼓励模型使用较小的权重。这通常会导致模型的复杂度降低，使得模型对于训练数据的小的变化不那么敏感，从而提高了模型的泛化能力。